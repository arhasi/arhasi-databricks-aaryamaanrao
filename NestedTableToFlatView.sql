-- Databricks SQL Query to create a "flattened" or un-nested database view over a table with complex metrics data stored as nested structs in columns

CREATE OR REPLACE VIEW dashboard_assessment_suite_view AS
SELECT
    assessment_id,
    assessment_name,
    evaluation_model,
    evaluation_variation,
    inserted_at as assessment_suite_insertion_timestamp,

    metrics_assessment['metrics_q1']['assessment_score_result'] as metrics_q1_assessment_score_result,
    metrics_assessment['metrics_q1']['evaluation_response'] as metrics_q1_evaluation_response,
    metrics_assessment['metrics_q1']['ground_input'] as metrics_q1_ground_input,
    metrics_assessment['metrics_q1']['input'] as metrics_q1_assessment_input,
    metrics_assessment['metrics_q1']['score'] as metrics_q1_score,
    metrics_assessment['metrics_q1']['standard_response'] as metrics_q1_standard_response,
    metrics_assessment['metrics_q1']['metrics_score']['bert_score_f1'] as metrics_q1_bert_score_f1,
    metrics_assessment['metrics_q1']['metrics_score']['bert_score_precision'] as metrics_q1_bert_score_precision,
    metrics_assessment['metrics_q1']['metrics_score']['bert_score_recall'] as metrics_q1_bert_score_recall,
    metrics_assessment['metrics_q1']['metrics_score']['bias'] as metrics_q1_bias,
    metrics_assessment['metrics_q1']['metrics_score']['code_eval'] as metrics_q1_code_eval,
    metrics_assessment['metrics_q1']['metrics_score']['coherence'] as metrics_q1_coherence,
    metrics_assessment['metrics_q1']['metrics_score']['conciseness'] as metrics_q1_conciseness,
    metrics_assessment['metrics_q1']['metrics_score']['controversiality'] as metrics_q1_controversiality,
    metrics_assessment['metrics_q1']['metrics_score']['correctness'] as metrics_q1_correctness,
    metrics_assessment['metrics_q1']['metrics_score']['criminality'] as metrics_q1_criminality,
    metrics_assessment['metrics_q1']['metrics_score']['embedding_distance'] as metrics_q1_embedding_distance,
    metrics_assessment['metrics_q1']['metrics_score']['google_bleu'] as metrics_q1_google_bleu,
    metrics_assessment['metrics_q1']['metrics_score']['hallucination'] as metrics_q1_hallucination,
    metrics_assessment['metrics_q1']['metrics_score']['harmful'] as metrics_q1_harmful,
    metrics_assessment['metrics_q1']['metrics_score']['helpfulness'] as metrics_q1_helpfulness,
    metrics_assessment['metrics_q1']['metrics_score']['insensitivity'] as metrics_q1_insensitivity,
    metrics_assessment['metrics_q1']['metrics_score']['maliciousness'] as metrics_q1_maliciousness,
    metrics_assessment['metrics_q1']['metrics_score']['meteor'] as metrics_q1_meteor,
    metrics_assessment['metrics_q1']['metrics_score']['misogyny'] as metrics_q1_misogyny,
    metrics_assessment['metrics_q1']['metrics_score']['pairwise_embedding_distance'] as metrics_q1_pairwise_embedding_distance,
    metrics_assessment['metrics_q1']['metrics_score']['pairwise_string_comparison'] as metrics_q1_pairwise_string_comparison,
    metrics_assessment['metrics_q1']['metrics_score']['perplexity'] as metrics_q1_perplexity,
    metrics_assessment['metrics_q1']['metrics_score']['regard_negative'] as metrics_q1_regard_negative,
    metrics_assessment['metrics_q1']['metrics_score']['regard_neutral'] as metrics_q1_regard_neutral,
    metrics_assessment['metrics_q1']['metrics_score']['regard_other'] as metrics_q1_regard_other,
    metrics_assessment['metrics_q1']['metrics_score']['regard_positive'] as metrics_q1_regard_positive,
    metrics_assessment['metrics_q1']['metrics_score']['relevance'] as metrics_q1_relevance,
    metrics_assessment['metrics_q1']['metrics_score']['string_distance'] as metrics_q1_string_distance,
    metrics_assessment['metrics_q1']['metrics_score']['toxicity'] as metrics_q1_toxicity,

    metrics_assessment['metrics_q2']['assessment_score_result'] as metrics_q2_assessment_score_result,
    metrics_assessment['metrics_q2']['evaluation_response'] as metrics_q2_evaluation_response,
    metrics_assessment['metrics_q2']['ground_input'] as metrics_q2_ground_input,
    metrics_assessment['metrics_q2']['input'] as metrics_q2_assessment_input,
    metrics_assessment['metrics_q2']['score'] as metrics_q2_score,
    metrics_assessment['metrics_q2']['standard_response'] as metrics_q2_standard_response,
    metrics_assessment['metrics_q2']['metrics_score']['bert_score_f1'] as metrics_q2_bert_score_f1,
    metrics_assessment['metrics_q2']['metrics_score']['bert_score_precision'] as metrics_q2_bert_score_precision,
    metrics_assessment['metrics_q2']['metrics_score']['bert_score_recall'] as metrics_q2_bert_score_recall,
    metrics_assessment['metrics_q2']['metrics_score']['bias'] as metrics_q2_bias,
    metrics_assessment['metrics_q2']['metrics_score']['code_eval'] as metrics_q2_code_eval,
    metrics_assessment['metrics_q2']['metrics_score']['coherence'] as metrics_q2_coherence,
    metrics_assessment['metrics_q2']['metrics_score']['conciseness'] as metrics_q2_conciseness,
    metrics_assessment['metrics_q2']['metrics_score']['controversiality'] as metrics_q2_controversiality,
    metrics_assessment['metrics_q2']['metrics_score']['correctness'] as metrics_q2_correctness,
    metrics_assessment['metrics_q2']['metrics_score']['criminality'] as metrics_q2_criminality,
    metrics_assessment['metrics_q2']['metrics_score']['embedding_distance'] as metrics_q2_embedding_distance,
    metrics_assessment['metrics_q2']['metrics_score']['google_bleu'] as metrics_q2_google_bleu,
    metrics_assessment['metrics_q2']['metrics_score']['hallucination'] as metrics_q2_hallucination,
    metrics_assessment['metrics_q2']['metrics_score']['harmful'] as metrics_q2_harmful,
    metrics_assessment['metrics_q2']['metrics_score']['helpfulness'] as metrics_q2_helpfulness,
    metrics_assessment['metrics_q2']['metrics_score']['insensitivity'] as metrics_q2_insensitivity,
    metrics_assessment['metrics_q2']['metrics_score']['maliciousness'] as metrics_q2_maliciousness,
    metrics_assessment['metrics_q2']['metrics_score']['meteor'] as metrics_q2_meteor,
    metrics_assessment['metrics_q2']['metrics_score']['misogyny'] as metrics_q2_misogyny,
    metrics_assessment['metrics_q2']['metrics_score']['pairwise_embedding_distance'] as metrics_q2_pairwise_embedding_distance,
    metrics_assessment['metrics_q2']['metrics_score']['pairwise_string_comparison'] as metrics_q2_pairwise_string_comparison,
    metrics_assessment['metrics_q2']['metrics_score']['perplexity'] as metrics_q2_perplexity,
    metrics_assessment['metrics_q2']['metrics_score']['regard_negative'] as metrics_q2_regard_negative,
    metrics_assessment['metrics_q2']['metrics_score']['regard_neutral'] as metrics_q2_regard_neutral,
    metrics_assessment['metrics_q2']['metrics_score']['regard_other'] as metrics_q2_regard_other,
    metrics_assessment['metrics_q2']['metrics_score']['regard_positive'] as metrics_q2_regard_positive,
    metrics_assessment['metrics_q2']['metrics_score']['relevance'] as metrics_q2_relevance,
    metrics_assessment['metrics_q2']['metrics_score']['string_distance'] as metrics_q2_string_distance,
    metrics_assessment['metrics_q2']['metrics_score']['toxicity'] as metrics_q2_toxicity,


    metrics_assessment['metrics_q3']['assessment_score_result'] as metrics_q3_assessment_score_result,
    metrics_assessment['metrics_q3']['evaluation_response'] as metrics_q3_evaluation_response,
    metrics_assessment['metrics_q3']['ground_input'] as metrics_q3_ground_input,
    metrics_assessment['metrics_q3']['input'] as metrics_q3_assessment_input,
    metrics_assessment['metrics_q3']['score'] as metrics_q3_score,
    metrics_assessment['metrics_q3']['standard_response'] as metrics_q3_standard_response,
    metrics_assessment['metrics_q3']['metrics_score']['bert_score_f1'] as metrics_q3_bert_score_f1,
    metrics_assessment['metrics_q3']['metrics_score']['bert_score_precision'] as metrics_q3_bert_score_precision,
    metrics_assessment['metrics_q3']['metrics_score']['bert_score_recall'] as metrics_q3_bert_score_recall,
    metrics_assessment['metrics_q3']['metrics_score']['bias'] as metrics_q3_bias,
    metrics_assessment['metrics_q3']['metrics_score']['code_eval'] as metrics_q3_code_eval,
    metrics_assessment['metrics_q3']['metrics_score']['coherence'] as metrics_q3_coherence,
    metrics_assessment['metrics_q3']['metrics_score']['conciseness'] as metrics_q3_conciseness,
    metrics_assessment['metrics_q3']['metrics_score']['controversiality'] as metrics_q3_controversiality,
    metrics_assessment['metrics_q3']['metrics_score']['correctness'] as metrics_q3_correctness,
    metrics_assessment['metrics_q3']['metrics_score']['criminality'] as metrics_q3_criminality,
    metrics_assessment['metrics_q3']['metrics_score']['embedding_distance'] as metrics_q3_embedding_distance,
    metrics_assessment['metrics_q3']['metrics_score']['google_bleu'] as metrics_q3_google_bleu,
    metrics_assessment['metrics_q3']['metrics_score']['hallucination'] as metrics_q3_hallucination,
    metrics_assessment['metrics_q3']['metrics_score']['harmful'] as metrics_q3_harmful,
    metrics_assessment['metrics_q3']['metrics_score']['helpfulness'] as metrics_q3_helpfulness,
    metrics_assessment['metrics_q3']['metrics_score']['insensitivity'] as metrics_q3_insensitivity,
    metrics_assessment['metrics_q3']['metrics_score']['maliciousness'] as metrics_q3_maliciousness,
    metrics_assessment['metrics_q3']['metrics_score']['meteor'] as metrics_q3_meteor,
    metrics_assessment['metrics_q3']['metrics_score']['misogyny'] as metrics_q3_misogyny,
    metrics_assessment['metrics_q3']['metrics_score']['pairwise_embedding_distance'] as metrics_q3_pairwise_embedding_distance,
    metrics_assessment['metrics_q3']['metrics_score']['pairwise_string_comparison'] as metrics_q3_pairwise_string_comparison,
    metrics_assessment['metrics_q3']['metrics_score']['perplexity'] as metrics_q3_perplexity,
    metrics_assessment['metrics_q3']['metrics_score']['regard_negative'] as metrics_q3_regard_negative,
    metrics_assessment['metrics_q3']['metrics_score']['regard_neutral'] as metrics_q3_regard_neutral,
    metrics_assessment['metrics_q3']['metrics_score']['regard_other'] as metrics_q3_regard_other,
    metrics_assessment['metrics_q3']['metrics_score']['regard_positive'] as metrics_q3_regard_positive,
    metrics_assessment['metrics_q3']['metrics_score']['relevance'] as metrics_q3_relevance,
    metrics_assessment['metrics_q3']['metrics_score']['string_distance'] as metrics_q3_string_distance,
    metrics_assessment['metrics_q3']['metrics_score']['toxicity'] as metrics_q3_toxicity,

    metrics_assessment['metrics_q4']['assessment_score_result'] as metrics_q4_assessment_score_result,
    metrics_assessment['metrics_q4']['evaluation_response'] as metrics_q4_evaluation_response,
    metrics_assessment['metrics_q4']['ground_input'] as metrics_q4_ground_input,
    metrics_assessment['metrics_q4']['input'] as metrics_q4_assessment_input,
    metrics_assessment['metrics_q4']['score'] as metrics_q4_score,
    metrics_assessment['metrics_q4']['standard_response'] as metrics_q4_standard_response,
    metrics_assessment['metrics_q4']['metrics_score']['bert_score_f1'] as metrics_q4_bert_score_f1,
    metrics_assessment['metrics_q4']['metrics_score']['bert_score_precision'] as metrics_q4_bert_score_precision,
    metrics_assessment['metrics_q4']['metrics_score']['bert_score_recall'] as metrics_q4_bert_score_recall,
    metrics_assessment['metrics_q4']['metrics_score']['bias'] as metrics_q4_bias,
    metrics_assessment['metrics_q4']['metrics_score']['code_eval'] as metrics_q4_code_eval,
    metrics_assessment['metrics_q4']['metrics_score']['coherence'] as metrics_q4_coherence,
    metrics_assessment['metrics_q4']['metrics_score']['conciseness'] as metrics_q4_conciseness,
    metrics_assessment['metrics_q4']['metrics_score']['controversiality'] as metrics_q4_controversiality,
    metrics_assessment['metrics_q4']['metrics_score']['correctness'] as metrics_q4_correctness,
    metrics_assessment['metrics_q4']['metrics_score']['criminality'] as metrics_q4_criminality,
    metrics_assessment['metrics_q4']['metrics_score']['embedding_distance'] as metrics_q4_embedding_distance,
    metrics_assessment['metrics_q4']['metrics_score']['google_bleu'] as metrics_q4_google_bleu,
    metrics_assessment['metrics_q4']['metrics_score']['hallucination'] as metrics_q4_hallucination,
    metrics_assessment['metrics_q4']['metrics_score']['harmful'] as metrics_q4_harmful,
    metrics_assessment['metrics_q4']['metrics_score']['helpfulness'] as metrics_q4_helpfulness,
    metrics_assessment['metrics_q4']['metrics_score']['insensitivity'] as metrics_q4_insensitivity,
    metrics_assessment['metrics_q4']['metrics_score']['maliciousness'] as metrics_q4_maliciousness,
    metrics_assessment['metrics_q4']['metrics_score']['meteor'] as metrics_q4_meteor,
    metrics_assessment['metrics_q4']['metrics_score']['misogyny'] as metrics_q4_misogyny,
    metrics_assessment['metrics_q4']['metrics_score']['pairwise_embedding_distance'] as metrics_q4_pairwise_embedding_distance,
    metrics_assessment['metrics_q4']['metrics_score']['pairwise_string_comparison'] as metrics_q4_pairwise_string_comparison,
    metrics_assessment['metrics_q4']['metrics_score']['perplexity'] as metrics_q4_perplexity,
    metrics_assessment['metrics_q4']['metrics_score']['regard_negative'] as metrics_q4_regard_negative,
    metrics_assessment['metrics_q4']['metrics_score']['regard_neutral'] as metrics_q4_regard_neutral,
    metrics_assessment['metrics_q4']['metrics_score']['regard_other'] as metrics_q4_regard_other,
    metrics_assessment['metrics_q4']['metrics_score']['regard_positive'] as metrics_q4_regard_positive,
    metrics_assessment['metrics_q4']['metrics_score']['relevance'] as metrics_q4_relevance,
    metrics_assessment['metrics_q4']['metrics_score']['string_distance'] as metrics_q4_string_distance,
    metrics_assessment['metrics_q4']['metrics_score']['toxicity'] as metrics_q4_toxicity,

    metrics_assessment['metrics_q5']['assessment_score_result'] as metrics_q5_assessment_score_result,
    metrics_assessment['metrics_q5']['evaluation_response'] as metrics_q5_evaluation_response,
    metrics_assessment['metrics_q5']['ground_input'] as metrics_q5_ground_input,
    metrics_assessment['metrics_q5']['input'] as metrics_q5_assessment_input,
    metrics_assessment['metrics_q5']['score'] as metrics_q5_score,
    metrics_assessment['metrics_q5']['standard_response'] as metrics_q5_standard_response,
    metrics_assessment['metrics_q5']['metrics_score']['bert_score_f1'] as metrics_q5_bert_score_f1,
    metrics_assessment['metrics_q5']['metrics_score']['bert_score_precision'] as metrics_q5_bert_score_precision,
    metrics_assessment['metrics_q5']['metrics_score']['bert_score_recall'] as metrics_q5_bert_score_recall,
    metrics_assessment['metrics_q5']['metrics_score']['bias'] as metrics_q5_bias,
    metrics_assessment['metrics_q5']['metrics_score']['code_eval'] as metrics_q5_code_eval,
    metrics_assessment['metrics_q5']['metrics_score']['coherence'] as metrics_q5_coherence,
    metrics_assessment['metrics_q5']['metrics_score']['conciseness'] as metrics_q5_conciseness,
    metrics_assessment['metrics_q5']['metrics_score']['controversiality'] as metrics_q5_controversiality,
    metrics_assessment['metrics_q5']['metrics_score']['correctness'] as metrics_q5_correctness,
    metrics_assessment['metrics_q5']['metrics_score']['criminality'] as metrics_q5_criminality,
    metrics_assessment['metrics_q5']['metrics_score']['embedding_distance'] as metrics_q5_embedding_distance,
    metrics_assessment['metrics_q5']['metrics_score']['google_bleu'] as metrics_q5_google_bleu,
    metrics_assessment['metrics_q5']['metrics_score']['hallucination'] as metrics_q5_hallucination,
    metrics_assessment['metrics_q5']['metrics_score']['harmful'] as metrics_q5_harmful,
    metrics_assessment['metrics_q5']['metrics_score']['helpfulness'] as metrics_q5_helpfulness,
    metrics_assessment['metrics_q5']['metrics_score']['insensitivity'] as metrics_q5_insensitivity,
    metrics_assessment['metrics_q5']['metrics_score']['maliciousness'] as metrics_q5_maliciousness,
    metrics_assessment['metrics_q5']['metrics_score']['meteor'] as metrics_q5_meteor,
    metrics_assessment['metrics_q5']['metrics_score']['misogyny'] as metrics_q5_misogyny,
    metrics_assessment['metrics_q5']['metrics_score']['pairwise_embedding_distance'] as metrics_q5_pairwise_embedding_distance,
    metrics_assessment['metrics_q5']['metrics_score']['pairwise_string_comparison'] as metrics_q5_pairwise_string_comparison,
    metrics_assessment['metrics_q5']['metrics_score']['perplexity'] as metrics_q5_perplexity,
    metrics_assessment['metrics_q5']['metrics_score']['regard_negative'] as metrics_q5_regard_negative,
    metrics_assessment['metrics_q5']['metrics_score']['regard_neutral'] as metrics_q5_regard_neutral,
    metrics_assessment['metrics_q5']['metrics_score']['regard_other'] as metrics_q5_regard_other,
    metrics_assessment['metrics_q5']['metrics_score']['regard_positive'] as metrics_q5_regard_positive,
    metrics_assessment['metrics_q5']['metrics_score']['relevance'] as metrics_q5_relevance,
    metrics_assessment['metrics_q5']['metrics_score']['string_distance'] as metrics_q5_string_distance,
    metrics_assessment['metrics_q5']['metrics_score']['toxicity'] as metrics_q5_toxicity,


    metrics_percentage,
    metrics_result,
    model,
    performance_percentage,
    performance_result,

    prompt_template_assessment['APPROACH']['fabricated_prompt'] as approach_prompt,
    prompt_template_assessment['APPROACH']['response'] as approach_response,
    prompt_template_assessment['APPROACH']['result'] as approach_result,
    prompt_template_assessment['APPROACH']['score'] as approach_score,

    prompt_template_assessment['BAB']['fabricated_prompt'] as bab_prompt,
    prompt_template_assessment['BAB']['response'] as bab_response,
    prompt_template_assessment['BAB']['result'] as bab_result,
    prompt_template_assessment['BAB']['score'] as bab_score,

    prompt_template_assessment['CARE']['fabricated_prompt'] as care_prompt,
    prompt_template_assessment['CARE']['response'] as care_response,
    prompt_template_assessment['CARE']['result'] as care_result,
    prompt_template_assessment['CARE']['score'] as care_score,

    prompt_template_assessment['CLEAR']['fabricated_prompt'] as clear_prompt,
    prompt_template_assessment['CLEAR']['response'] as clear_response,
    prompt_template_assessment['CLEAR']['result'] as clear_result,
    prompt_template_assessment['CLEAR']['score'] as clear_score,


    prompt_template_assessment['PACT']['fabricated_prompt'] as pact_prompt,
    prompt_template_assessment['PACT']['response'] as pact_response,
    prompt_template_assessment['PACT']['result'] as pact_result,
    prompt_template_assessment['PACT']['score'] as pact_score,

    prompt_template_assessment['RASCEF']['fabricated_prompt'] as rascef_prompt,
    prompt_template_assessment['RASCEF']['response'] as rascef_response,
    prompt_template_assessment['RASCEF']['result'] as rascef_result,
    prompt_template_assessment['RASCEF']['score'] as rascef_score,

    prompt_template_assessment['RISE']['fabricated_prompt'] as rise_prompt,
    prompt_template_assessment['RISE']['response'] as rise_response,
    prompt_template_assessment['RISE']['result'] as rise_result,
    prompt_template_assessment['RISE']['score'] as rise_score,

    prompt_template_assessment['RTF']['fabricated_prompt'] as rtf_prompt,
    prompt_template_assessment['RTF']['response'] as rtf_response,
    prompt_template_assessment['RTF']['result'] as rtf_result,
    prompt_template_assessment['RTF']['score'] as rtf_score,

    prompt_template_assessment['SAID']['fabricated_prompt'] as said_prompt,
    prompt_template_assessment['SAID']['response'] as said_response,
    prompt_template_assessment['SAID']['result'] as said_result,
    prompt_template_assessment['SAID']['score'] as said_score,

    prompt_template_assessment['STAR']['fabricated_prompt'] as star_prompt,
    prompt_template_assessment['STAR']['response'] as star_response,
    prompt_template_assessment['STAR']['result'] as star_result,
    prompt_template_assessment['STAR']['score'] as star_score,

    prompt_template_assessment['TAG']['fabricated_prompt'] as tag_prompt,
    prompt_template_assessment['TAG']['response'] as tag_response,
    prompt_template_assessment['TAG']['result'] as tag_result,
    prompt_template_assessment['TAG']['score'] as tag_score,

    prompt_template_assessment['TRACE']['fabricated_prompt'] as trace_prompt,
    prompt_template_assessment['TRACE']['response'] as trace_response,
    prompt_template_assessment['TRACE']['result'] as trace_result,
    prompt_template_assessment['TRACE']['score'] as trace_score,

    response_template_assessment['BIAS_CHECK']['response'] as response_bias_check_response,
    response_template_assessment['BIAS_CHECK']['result'] as response_bias_check_result,
    response_template_assessment['BIAS_CHECK']['score'] as response_bias_check_score,

    response_template_assessment['CONTEXT_ANSWERING']['response'] as response_context_answering_response,
    response_template_assessment['CONTEXT_ANSWERING']['result'] as response_context_answering_result,
    response_template_assessment['CONTEXT_ANSWERING']['score'] as response_context_answering_score,

    response_template_assessment['CONTEXT_RELEVANCE']['response'] as response_context_relevance_response,
    response_template_assessment['CONTEXT_RELEVANCE']['result'] as response_context_relevance_result,
    response_template_assessment['CONTEXT_RELEVANCE']['score'] as response_context_relevance_score,

    response_template_assessment['REASONING']['response'] as response_reasoning_response,
    response_template_assessment['REASONING']['result'] as response_reasoning_result,
    response_template_assessment['REASONING']['score'] as response_reasoning_score,

    response_template_assessment['THINK_STEP_BY_STEP']['response'] as response_think_step_by_step_response,
    response_template_assessment['THINK_STEP_BY_STEP']['result'] as response_think_step_by_step_result,
    response_template_assessment['THINK_STEP_BY_STEP']['score'] as response_think_step_by_step_score,



    safety_assessment['cyber_security_assessment']['cyber_security_check_assessment'] as cyber_security_check_assessment,
    safety_assessment['cyber_security_assessment']['cyber_security_score_counts']['excellent'] as cyber_security_score_counts_excellent,
    safety_assessment['cyber_security_assessment']['cyber_security_score_counts']['good'] as cyber_security_score_counts_good,
    safety_assessment['cyber_security_assessment']['cyber_security_score_counts']['moderate'] as cyber_security_score_counts_moderate,
    safety_assessment['cyber_security_assessment']['cyber_security_score_counts']['poor'] as cyber_security_score_counts_poor,

    safety_assessment['cyber_security_assessment']['cyber_security_score_percentages']['excellent'] as cyber_security_score_percentages_excellent,
    safety_assessment['cyber_security_assessment']['cyber_security_score_percentages']['good'] as cyber_security_score_percentages_good,
    safety_assessment['cyber_security_assessment']['cyber_security_score_percentages']['moderate'] as cyber_security_score_percentages_moderate,
    safety_assessment['cyber_security_assessment']['cyber_security_score_percentages']['poor'] as cyber_security_score_percentages_poor,

    safety_assessment['ethical_conduct_assessment']['ethical_conduct_check_assessment'] as ethical_conduct_check_assessment,
    safety_assessment['ethical_conduct_assessment']['ethical_conduct_score_counts']['excellent'] as ethical_conduct_score_counts_excellent,
    safety_assessment['ethical_conduct_assessment']['ethical_conduct_score_counts']['good'] as ethical_conduct_score_counts_good,
    safety_assessment['ethical_conduct_assessment']['ethical_conduct_score_counts']['moderate'] as ethical_conduct_score_counts_moderate,
    safety_assessment['ethical_conduct_assessment']['ethical_conduct_score_counts']['poor'] as ethical_conduct_score_counts_poor,

    safety_assessment['ethical_conduct_assessment']['ethical_conduct_score_percentages']['excellent'] as ethical_conduct_score_percentages_excellent,
    safety_assessment['ethical_conduct_assessment']['ethical_conduct_score_percentages']['good'] as ethical_conduct_score_percentages_good,
    safety_assessment['ethical_conduct_assessment']['ethical_conduct_score_percentages']['moderate'] as ethical_conduct_score_percentages_moderate,
    safety_assessment['ethical_conduct_assessment']['ethical_conduct_score_percentages']['poor'] as ethical_conduct_score_percentages_poor,

    safety_assessment['mental_health_assessment']['mental_health_check_assessment'] as mental_health_check_assessment,
    safety_assessment['mental_health_assessment']['mental_health_score_counts']['excellent'] as mental_health_score_counts_excellent,
    safety_assessment['mental_health_assessment']['mental_health_score_counts']['good'] as mental_health_score_counts_good,
    safety_assessment['mental_health_assessment']['mental_health_score_counts']['moderate'] as mental_health_score_counts_moderate,
    safety_assessment['mental_health_assessment']['mental_health_score_counts']['poor'] as mental_health_score_counts_poor,

    safety_assessment['mental_health_assessment']['mental_health_score_percentages']['excellent'] as mental_health_score_percentages_excellent,
    safety_assessment['mental_health_assessment']['mental_health_score_percentages']['good'] as mental_health_score_percentages_good,
    safety_assessment['mental_health_assessment']['mental_health_score_percentages']['moderate'] as mental_health_score_percentages_moderate,
    safety_assessment['mental_health_assessment']['mental_health_score_percentages']['poor'] as mental_health_score_percentages_poor,
    
    safety_assessment['online_safety_assessment']['online_safety_check_assessment'] as online_safety_check_assessment,
    safety_assessment['online_safety_assessment']['online_safety_score_counts']['excellent'] as online_safety_score_counts_excellent,
    safety_assessment['online_safety_assessment']['online_safety_score_counts']['good'] as online_safety_score_counts_good,
    safety_assessment['online_safety_assessment']['online_safety_score_counts']['moderate'] as online_safety_score_counts_moderate,
    safety_assessment['online_safety_assessment']['online_safety_score_counts']['poor'] as online_safety_score_counts_poor,

    safety_assessment['online_safety_assessment']['online_safety_score_percentages']['excellent'] as online_safety_score_percentages_excellent,
    safety_assessment['online_safety_assessment']['online_safety_score_percentages']['good'] as online_safety_score_percentages_good,
    safety_assessment['online_safety_assessment']['online_safety_score_percentages']['moderate'] as online_safety_score_percentages_moderate,
    safety_assessment['online_safety_assessment']['online_safety_score_percentages']['poor'] as online_safety_score_percentages_poor,

    safety_assessment['safety_response']['safetyq_1']['category'] as safetyq_1_category,
    safety_assessment['safety_response']['safetyq_1']['result'] as safetyq_1_result,
    safety_assessment['safety_response']['safetyq_1']['score'] as safetyq_1_score,
    safety_assessment['safety_response']['safetyq_1']['standard_response'] as safetyq_1_standard_response,

    safety_assessment['safety_response']['safetyq_2']['category'] as safetyq_2_category,
    safety_assessment['safety_response']['safetyq_2']['result'] as safetyq_2_result,
    safety_assessment['safety_response']['safetyq_2']['score'] as safetyq_2_score,
    safety_assessment['safety_response']['safetyq_2']['standard_response'] as safetyq_2_standard_response,

    safety_assessment['safety_response']['safetyq_3']['category'] as safetyq_3_category,
    safety_assessment['safety_response']['safetyq_3']['result'] as safetyq_3_result,
    safety_assessment['safety_response']['safetyq_3']['score'] as safetyq_3_score,
    safety_assessment['safety_response']['safetyq_3']['standard_response'] as safetyq_3_standard_response,

    safety_assessment['safety_response']['safetyq_4']['category'] as safetyq_4_category,
    safety_assessment['safety_response']['safetyq_4']['result'] as safetyq_4_result,
    safety_assessment['safety_response']['safetyq_4']['score'] as safetyq_4_score,
    safety_assessment['safety_response']['safetyq_4']['standard_response'] as safetyq_4_standard_response,

    safety_assessment['safety_response']['safetyq_5']['category'] as safetyq_5_category,
    safety_assessment['safety_response']['safetyq_5']['result'] as safetyq_5_result,
    safety_assessment['safety_response']['safetyq_5']['score'] as safetyq_5_score,
    safety_assessment['safety_response']['safetyq_5']['standard_response'] as safetyq_5_standard_response,

    safety_assessment['safety_response']['safetyq_6']['category'] as safetyq_6_category,
    safety_assessment['safety_response']['safetyq_6']['result'] as safetyq_6_result,
    safety_assessment['safety_response']['safetyq_6']['score'] as safetyq_6_score,
    safety_assessment['safety_response']['safetyq_6']['standard_response'] as safetyq_6_standard_response,

    safety_assessment['safety_response']['safetyq_7']['category'] as safetyq_7_category,
    safety_assessment['safety_response']['safetyq_7']['result'] as safetyq_7_result,
    safety_assessment['safety_response']['safetyq_7']['score'] as safetyq_7_score,
    safety_assessment['safety_response']['safetyq_7']['standard_response'] as safetyq_7_standard_response,

    safety_assessment['safety_response']['safetyq_8']['category'] as safetyq_8_category,
    safety_assessment['safety_response']['safetyq_8']['result'] as safetyq_8_result,
    safety_assessment['safety_response']['safetyq_8']['score'] as safetyq_8_score,
    safety_assessment['safety_response']['safetyq_8']['standard_response'] as safetyq_8_standard_response,

    safety_assessment['safety_response']['safetyq_9']['category'] as safetyq_9_category,
    safety_assessment['safety_response']['safetyq_9']['result'] as safetyq_9_result,
    safety_assessment['safety_response']['safetyq_9']['score'] as safetyq_9_score,
    safety_assessment['safety_response']['safetyq_9']['standard_response'] as safetyq_9_standard_response,

    safety_assessment['safety_response']['safetyq_10']['category'] as safetyq_10_category,
    safety_assessment['safety_response']['safetyq_10']['result'] as safetyq_10_result,
    safety_assessment['safety_response']['safetyq_10']['score'] as safetyq_10_score,
    safety_assessment['safety_response']['safetyq_10']['standard_response'] as safetyq_10_standard_response,

    safety_assessment['safety_response']['safetyq_11']['category'] as safetyq_11_category,
    safety_assessment['safety_response']['safetyq_11']['result'] as safetyq_11_result,
    safety_assessment['safety_response']['safetyq_11']['score'] as safetyq_11_score,
    safety_assessment['safety_response']['safetyq_11']['standard_response'] as safetyq_11_standard_response,

    safety_assessment['safety_response']['safetyq_12']['category'] as safetyq_12_category,
    safety_assessment['safety_response']['safetyq_12']['result'] as safetyq_12_result,
    safety_assessment['safety_response']['safetyq_12']['score'] as safetyq_12_score,
    safety_assessment['safety_response']['safetyq_12']['standard_response'] as safetyq_12_standard_response,

    safety_assessment['safety_response']['safetyq_13']['category'] as safetyq_13_category,
    safety_assessment['safety_response']['safetyq_13']['result'] as safetyq_13_result,
    safety_assessment['safety_response']['safetyq_13']['score'] as safetyq_13_score,
    safety_assessment['safety_response']['safetyq_13']['standard_response'] as safetyq_13_standard_response,

    safety_assessment['safety_response']['safetyq_14']['category'] as safetyq_14_category,
    safety_assessment['safety_response']['safetyq_14']['result'] as safetyq_14_result,
    safety_assessment['safety_response']['safetyq_14']['score'] as safetyq_14_score,
    safety_assessment['safety_response']['safetyq_14']['standard_response'] as safetyq_14_standard_response,

    safety_assessment['safety_response']['safetyq_15']['category'] as safetyq_15_category,
    safety_assessment['safety_response']['safetyq_15']['result'] as safetyq_15_result,
    safety_assessment['safety_response']['safetyq_15']['score'] as safetyq_15_score,
    safety_assessment['safety_response']['safetyq_15']['standard_response'] as safetyq_15_standard_response,

    safety_assessment['safety_response']['safetyq_16']['category'] as safetyq_16_category,
    safety_assessment['safety_response']['safetyq_16']['result'] as safetyq_16_result,
    safety_assessment['safety_response']['safetyq_16']['score'] as safetyq_16_score,
    safety_assessment['safety_response']['safetyq_16']['standard_response'] as safetyq_16_standard_response,

    safety_assessment['safety_response']['safetyq_17']['category'] as safetyq_17_category,
    safety_assessment['safety_response']['safetyq_17']['result'] as safetyq_17_result,
    safety_assessment['safety_response']['safetyq_17']['score'] as safetyq_17_score,
    safety_assessment['safety_response']['safetyq_17']['standard_response'] as safetyq_17_standard_response,

    safety_assessment['safety_response']['safetyq_18']['category'] as safetyq_18_category,
    safety_assessment['safety_response']['safetyq_18']['result'] as safetyq_18_result,
    safety_assessment['safety_response']['safetyq_18']['score'] as safetyq_18_score,
    safety_assessment['safety_response']['safetyq_18']['standard_response'] as safetyq_18_standard_response,

    safety_assessment['safety_response']['safetyq_19']['category'] as safetyq_19_category,
    safety_assessment['safety_response']['safetyq_19']['result'] as safetyq_19_result,
    safety_assessment['safety_response']['safetyq_19']['score'] as safetyq_19_score,
    safety_assessment['safety_response']['safetyq_19']['standard_response'] as safetyq_19_standard_response,

    safety_assessment['safety_response']['safetyq_20']['category'] as safetyq_20_category,
    safety_assessment['safety_response']['safetyq_20']['result'] as safetyq_20_result,
    safety_assessment['safety_response']['safetyq_20']['score'] as safetyq_20_score,
    safety_assessment['safety_response']['safetyq_20']['standard_response'] as safetyq_20_standard_response,

    safety_percentage,
    safety_result,

    security_assessment['data_exfilteration_assessment']['data_exfilteration_check_assessment'] as data_exfilteration_check_assessment,

    security_assessment['data_exfilteration_assessment']['data_exfilteration_score_counts']['excellent'] as data_exfilteration_score_counts_excellent,
    security_assessment['data_exfilteration_assessment']['data_exfilteration_score_counts']['good'] as data_exfilteration_score_counts_good,
    security_assessment['data_exfilteration_assessment']['data_exfilteration_score_counts']['moderate'] as data_exfilteration_score_counts_moderate,
    security_assessment['data_exfilteration_assessment']['data_exfilteration_score_counts']['poor'] as data_exfilteration_score_counts_poor,

    security_assessment['data_exfilteration_assessment']['data_exfilteration_score_percentages']['excellent'] as data_exfilteration_score_percentages_excellent,
    security_assessment['data_exfilteration_assessment']['data_exfilteration_score_percentages']['good'] as data_exfilteration_score_percentages_good,
    security_assessment['data_exfilteration_assessment']['data_exfilteration_score_percentages']['moderate'] as data_exfilteration_score_percentages_moderate,
    security_assessment['data_exfilteration_assessment']['data_exfilteration_score_percentages']['poor'] as data_exfilteration_score_percentages_poor,

    security_assessment['phishing_assessment']['phishing_check_assessment'] as phishing_check_assessment,

    security_assessment['phishing_assessment']['phishing_score_counts']['excellent'] as phishing_score_counts_excellent,
    security_assessment['phishing_assessment']['phishing_score_counts']['good'] as phishing_score_counts_good,
    security_assessment['phishing_assessment']['phishing_score_counts']['moderate'] as phishing_score_counts_moderate,
    security_assessment['phishing_assessment']['phishing_score_counts']['poor'] as phishing_score_counts_poor,

    security_assessment['phishing_assessment']['phishing_score_percentages']['excellent'] as phishing_score_percentages_excellent,
    security_assessment['phishing_assessment']['phishing_score_percentages']['good'] as phishing_score_percentages_good,
    security_assessment['phishing_assessment']['phishing_score_percentages']['moderate'] as phishing_score_percentages_moderate,
    security_assessment['phishing_assessment']['phishing_score_percentages']['poor'] as phishing_score_percentages_poor,

    security_assessment['pii_assessment']['pii_check_assessment'] as pii_check_assessment,

    security_assessment['pii_assessment']['pii_score_counts']['excellent'] as pii_score_counts_excellent,
    security_assessment['pii_assessment']['pii_score_counts']['good'] as pii_score_counts_good,
    security_assessment['pii_assessment']['pii_score_counts']['moderate'] as pii_score_counts_moderate,
    security_assessment['pii_assessment']['pii_score_counts']['poor'] as pii_score_counts_poor,

    security_assessment['pii_assessment']['pii_score_percentages']['excellent'] as pii_score_percentages_excellent,
    security_assessment['pii_assessment']['pii_score_percentages']['good'] as pii_score_percentages_good,
    security_assessment['pii_assessment']['pii_score_percentages']['moderate'] as pii_score_percentages_moderate,
    security_assessment['pii_assessment']['pii_score_percentages']['poor'] as pii_score_percentages_poor,

    security_assessment['prompt_leakage_assessment']['prompt_leakage_check_assessment'] as prompt_leakage_check_assessment,

    security_assessment['prompt_leakage_assessment']['prompt_leakage_score_counts']['excellent'] as prompt_leakage_score_counts_excellent,
    security_assessment['prompt_leakage_assessment']['prompt_leakage_score_counts']['good'] as prompt_leakage_score_counts_good,
    security_assessment['prompt_leakage_assessment']['prompt_leakage_score_counts']['moderate'] as prompt_leakage_score_counts_moderate,
    security_assessment['prompt_leakage_assessment']['prompt_leakage_score_counts']['poor'] as prompt_leakage_score_counts_poor,

    security_assessment['prompt_leakage_assessment']['prompt_leakage_score_percentages']['excellent'] as prompt_leakage_score_percentages_excellent,
    security_assessment['prompt_leakage_assessment']['prompt_leakage_score_percentages']['good'] as prompt_leakage_score_percentages_good,
    security_assessment['prompt_leakage_assessment']['prompt_leakage_score_percentages']['moderate'] as prompt_leakage_score_percentages_moderate,
    security_assessment['prompt_leakage_assessment']['prompt_leakage_score_percentages']['poor'] as prompt_leakage_score_percentages_poor,

    security_assessment['security_response']['securityq_1']['category'] as security_responseq_1_category,
    security_assessment['security_response']['securityq_1']['result'] as security_responseq_1_result,
    security_assessment['security_response']['securityq_1']['score'] as security_responseq_1_score,
    security_assessment['security_response']['securityq_1']['standard_response'] as security_responseq_1_standard_response,

    security_assessment['security_response']['securityq_2']['category'] as security_responseq_2_category,
    security_assessment['security_response']['securityq_2']['result'] as security_responseq_2_result,
    security_assessment['security_response']['securityq_2']['score'] as security_responseq_2_score,
    security_assessment['security_response']['securityq_2']['standard_response'] as security_responseq_2_standard_response,

    security_assessment['security_response']['securityq_3']['category'] as security_responseq_3_category,
    security_assessment['security_response']['securityq_3']['result'] as security_responseq_3_result,
    security_assessment['security_response']['securityq_3']['score'] as security_responseq_3_score,
    security_assessment['security_response']['securityq_3']['standard_response'] as security_responseq_3_standard_response,

    security_assessment['security_response']['securityq_4']['category'] as security_responseq_4_category,
    security_assessment['security_response']['securityq_4']['result'] as security_responseq_4_result,
    security_assessment['security_response']['securityq_4']['score'] as security_responseq_4_score,
    security_assessment['security_response']['securityq_4']['standard_response'] as security_responseq_4_standard_response,

    security_assessment['security_response']['securityq_5']['category'] as security_responseq_5_category,
    security_assessment['security_response']['securityq_5']['result'] as security_responseq_5_result,
    security_assessment['security_response']['securityq_5']['score'] as security_responseq_5_score,
    security_assessment['security_response']['securityq_5']['standard_response'] as security_responseq_5_standard_response,

    security_assessment['security_response']['securityq_6']['category'] as security_responseq_6_category,
    security_assessment['security_response']['securityq_6']['result'] as security_responseq_6_result,
    security_assessment['security_response']['securityq_6']['score'] as security_responseq_6_score,
    security_assessment['security_response']['securityq_6']['standard_response'] as security_responseq_6_standard_response,

    security_assessment['security_response']['securityq_7']['category'] as security_responseq_7_category,
    security_assessment['security_response']['securityq_7']['result'] as security_responseq_7_result,
    security_assessment['security_response']['securityq_7']['score'] as security_responseq_7_score,
    security_assessment['security_response']['securityq_7']['standard_response'] as security_responseq_7_standard_response,

    security_assessment['security_response']['securityq_8']['category'] as security_responseq_8_category,
    security_assessment['security_response']['securityq_8']['result'] as security_responseq_8_result,
    security_assessment['security_response']['securityq_8']['score'] as security_responseq_8_score,
    security_assessment['security_response']['securityq_8']['standard_response'] as security_responseq_8_standard_response,

    security_assessment['security_response']['securityq_9']['category'] as security_responseq_9_category,
    security_assessment['security_response']['securityq_9']['result'] as security_responseq_9_result,
    security_assessment['security_response']['securityq_9']['score'] as security_responseq_9_score,
    security_assessment['security_response']['securityq_9']['standard_response'] as security_responseq_9_standard_response,

    security_assessment['security_response']['securityq_10']['category'] as security_responseq_10_category,
    security_assessment['security_response']['securityq_10']['result'] as security_responseq_10_result,
    security_assessment['security_response']['securityq_10']['score'] as security_responseq_10_score,
    security_assessment['security_response']['securityq_10']['standard_response'] as security_responseq_10_standard_response,

    security_assessment['security_response']['securityq_11']['category'] as security_responseq_11_category,
    security_assessment['security_response']['securityq_11']['result'] as security_responseq_11_result,
    security_assessment['security_response']['securityq_11']['score'] as security_responseq_11_score,
    security_assessment['security_response']['securityq_11']['standard_response'] as security_responseq_11_standard_response,

    security_assessment['security_response']['securityq_12']['category'] as security_responseq_12_category,
    security_assessment['security_response']['securityq_12']['result'] as security_responseq_12_result,
    security_assessment['security_response']['securityq_12']['score'] as security_responseq_12_score,
    security_assessment['security_response']['securityq_12']['standard_response'] as security_responseq_12_standard_response,

    security_assessment['security_response']['securityq_13']['category'] as security_responseq_13_category,
    security_assessment['security_response']['securityq_13']['result'] as security_responseq_13_result,
    security_assessment['security_response']['securityq_13']['score'] as security_responseq_13_score,
    security_assessment['security_response']['securityq_13']['standard_response'] as security_responseq_13_standard_response,

    security_assessment['security_response']['securityq_14']['category'] as security_responseq_14_category,
    security_assessment['security_response']['securityq_14']['result'] as security_responseq_14_result,
    security_assessment['security_response']['securityq_14']['score'] as security_responseq_14_score,
    security_assessment['security_response']['securityq_14']['standard_response'] as security_responseq_14_standard_response,

    security_assessment['security_response']['securityq_15']['category'] as security_responseq_15_category,
    security_assessment['security_response']['securityq_15']['result'] as security_responseq_15_result,
    security_assessment['security_response']['securityq_15']['score'] as security_responseq_15_score,
    security_assessment['security_response']['securityq_15']['standard_response'] as security_responseq_15_standard_response,

    security_assessment['security_response']['securityq_16']['category'] as security_responseq_16_category,
    security_assessment['security_response']['securityq_16']['result'] as security_responseq_16_result,
    security_assessment['security_response']['securityq_16']['score'] as security_responseq_16_score,
    security_assessment['security_response']['securityq_16']['standard_response'] as security_responseq_16_standard_response,

    security_assessment['security_response']['securityq_17']['category'] as security_responseq_17_category,
    security_assessment['security_response']['securityq_17']['result'] as security_responseq_17_result,
    security_assessment['security_response']['securityq_17']['score'] as security_responseq_17_score,
    security_assessment['security_response']['securityq_17']['standard_response'] as security_responseq_17_standard_response,

    security_assessment['security_response']['securityq_18']['category'] as security_responseq_18_category,
    security_assessment['security_response']['securityq_18']['result'] as security_responseq_18_result,
    security_assessment['security_response']['securityq_18']['score'] as security_responseq_18_score,
    security_assessment['security_response']['securityq_18']['standard_response'] as security_responseq_18_standard_response,

    security_assessment['security_response']['securityq_19']['category'] as security_responseq_19_category,
    security_assessment['security_response']['securityq_19']['result'] as security_responseq_19_result,
    security_assessment['security_response']['securityq_19']['score'] as security_responseq_19_score,
    security_assessment['security_response']['securityq_19']['standard_response'] as security_responseq_19_standard_response,


    security_assessment['security_response']['securityq_20']['category'] as security_responseq_20_category,
    security_assessment['security_response']['securityq_20']['result'] as security_responseq_20_result,
    security_assessment['security_response']['securityq_20']['score'] as security_responseq_20_score,
    security_assessment['security_response']['securityq_20']['standard_response'] as security_responseq_20_standard_response,


    security_percentage,
    security_result,

    standard_response_assessment['input'] as standard_response_assessment_input,
    standard_response_assessment['llm_response'] as standard_response_assessment_llm_response,
    standard_response_assessment['result'] as standard_response_assessment_result,
    standard_response_assessment['score'] as standard_response_assessment_score,

    topical_assessment["topical_counts"]["poor"] AS topical_assessment_counts_poor,
    topical_assessment["topical_counts"]["moderate"] AS topical_assessment_counts_moderate,
    topical_assessment["topical_counts"]["good"] AS topical_assessment_counts_good,
    topical_assessment["topical_counts"]["excellent"] AS topical_assessment_counts_excellent,

    topical_assessment["topical_percentages"]["poor"] AS topical_assessment_percentages_poor,
    topical_assessment["topical_percentages"]["moderate"] AS topical_assessment_percentages_moderate,
    topical_assessment["topical_percentages"]["good"] AS topical_assessment_percentages_good,
    topical_assessment["topical_percentages"]["excellent"] AS topical_assessment_percentages_excellent,
   

    topical_assessment['topical_response']['topicalq_1']['result'] as topical_responseq_1_result,
    topical_assessment['topical_response']['topicalq_1']['score'] as topical_responseq_1_score,
    topical_assessment['topical_response']['topicalq_1']['standard_response'] as topical_responseq_1_standard_response,

    topical_assessment['topical_response']['topicalq_2']['result'] as topical_responseq_2_result,
    topical_assessment['topical_response']['topicalq_2']['score'] as topical_responseq_2_score,
    topical_assessment['topical_response']['topicalq_2']['standard_response'] as topical_responseq_2_standard_response,

    topical_assessment['topical_response']['topicalq_3']['result'] as topical_responseq_3_result,
    topical_assessment['topical_response']['topicalq_3']['score'] as topical_responseq_3_score,
    topical_assessment['topical_response']['topicalq_3']['standard_response'] as topical_responseq_3_standard_response,

    topical_assessment['topical_response']['topicalq_4']['result'] as topical_responseq_4_result,
    topical_assessment['topical_response']['topicalq_4']['score'] as topical_responseq_4_score,
    topical_assessment['topical_response']['topicalq_4']['standard_response'] as topical_responseq_4_standard_response,

    topical_assessment['topical_response']['topicalq_5']['result'] as topical_responseq_5_result,
    topical_assessment['topical_response']['topicalq_5']['score'] as topical_responseq_5_score,
    topical_assessment['topical_response']['topicalq_5']['standard_response'] as topical_responseq_5_standard_response,

    topical_assessment['topical_response']['topicalq_6']['result'] as topical_responseq_6_result,
    topical_assessment['topical_response']['topicalq_6']['score'] as topical_responseq_6_score,
    topical_assessment['topical_response']['topicalq_6']['standard_response'] as topical_responseq_6_standard_response,
    topical_assessment["topical_result"] as topical_assessment_result,

    topical_percentage,
    topical_result,
    use_rag,
    variation
FROM
    rapid_applications.assessment_suite
;
